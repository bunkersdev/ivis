<workflow-app name="WF_MOSC_DEV_IVIS_JDA_USR_PERMISSION_ACCESS" xmlns="uri:oozie:workflow:0.4">
    <global>
	    <job-xml>${hiveSite}</job-xml>
	    <job-xml>${hbasesite}</job-xml>
        <configuration>
            <property>
                <name>mapreduce.job.queuename</name>
                <value>${queueName}</value>
            </property>
        </configuration>
    </global>
    <credentials>
        <credential name='hcat_creds' type='hcat'>
            <property>
                <name>hcat.metastore.uri</name>
                <value>${metastore}</value>
            </property>
            <property>
                <name>hcat.metastore.principal</name>
                <value>${metastore_principal}</value>
            </property>
        </credential>
		
		<credential name='hbase' type='hbase'/>
    </credentials>   

    <start to="fork_sqoop"/>
	
	<fork name="fork_sqoop">
	  	<path start="sqoop_usr_permission_master"/>
		<path start="sqoop_scp_web_usr_access_vw"/>
	</fork>
	
		<action name="sqoop_usr_permission_master">
        <sqoop xmlns="uri:oozie:sqoop-action:0.2">
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <prepare>
              <delete path="${nameNode}${sqoop_usr_permission_master_destination}"/>
            </prepare>
            <configuration>
                <property>
                    <name>mapred.job.queue.name</name>
                    <value>${queueName}</value>
                </property>
            </configuration>
        
           <arg>import</arg>
            <arg>--connect</arg>
            <arg>${ivisJdbcConnect}</arg>
            <arg>--username</arg>
            <arg>${ivisSqoopuser}</arg>
            <arg>--password-file</arg>
            <arg>${ivisPasswordfile}</arg>
            <arg>--query</arg>
            <arg>
                   SELECT * FROM ${stgmgr_schema}.USR_PERMISSION_MASTER WHERE $CONDITIONS
            </arg>
			<arg>--compression-codec</arg>
			<arg>org.apache.hadoop.io.compress.GzipCodec</arg>
			<arg>--fields-terminated-by</arg>
			<arg>\001</arg>
			<arg>--null-string</arg>
			<arg>'\\N'</arg>
			<arg>--null-non-string</arg>
			<arg>'\\N'</arg>
            <arg>--target-dir</arg>
            <arg>${sqoop_usr_permission_master_destination}</arg>
			<arg>-m</arg>
            <arg>1</arg>

        </sqoop>
        <ok to="join_sqoop_merge"/>
        <error to="failureEmail"/>
    </action>
		
	<action name="sqoop_scp_web_usr_access_vw">
        <sqoop xmlns="uri:oozie:sqoop-action:0.2">
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <prepare>
              <delete path="${nameNode}${sqoop_scp_web_usr_access_vw_destination}"/>
            </prepare>
            <configuration>
                <property>
                    <name>mapred.job.queue.name</name>
                    <value>${queueName}</value>
                </property>
            </configuration>
        
           <arg>import</arg>
            <arg>--connect</arg>
            <arg>${ivisJdbcConnect}</arg>
            <arg>--username</arg>
            <arg>${ivisSqoopuser}</arg>
            <arg>--password-file</arg>
            <arg>${ivisPasswordfile}</arg>
            <arg>--query</arg>
            <arg>
                   SELECT * FROM ${stgmgr_schema}.SCP_WEB_USR_ACCESS_VW WHERE $CONDITIONS
            </arg>
			<arg>--compression-codec</arg>
			<arg>org.apache.hadoop.io.compress.GzipCodec</arg>
			<arg>--fields-terminated-by</arg>
			<arg>\001</arg>
			<arg>--null-string</arg>
			<arg>'\\N'</arg>
			<arg>--null-non-string</arg>
			<arg>'\\N'</arg>
            <arg>--target-dir</arg>
            <arg>${sqoop_scp_web_usr_access_vw_destination}</arg>
			<arg>-m</arg>
            <arg>1</arg>

        </sqoop>
        <ok to="join_sqoop_merge"/>
        <error to="failureEmail"/>
    </action>
	
	
	<join name="join_sqoop_merge" to="insert_overwrite_lnd_stg"/>
		
	<fork name="insert_overwrite_lnd_stg">
		<path start="insert_overwrite_scp_web_usr_access_vw"/>
		<path start="insert_overwrite_usr_permission_master"/>
	</fork>
	
	     <!-- The hive scripts does  insert overwrite to tables in staging area-->
    <action name="insert_overwrite_scp_web_usr_access_vw" cred="hcat_creds">
        <hive xmlns="uri:oozie:hive-action:0.2">
		 <job-tracker>${jobTracker}</job-tracker>
         <name-node>${nameNode}</name-node>
		<prepare>
              <delete path="${nameNode}${scp_web_usr_access_vw_staging_location}/*"/>
        </prepare>
		 <configuration>
                <property>
                    <name>mapred.job.queue.name</name>
                    <value>${queueName}</value>
                </property>
         </configuration>
            <script>${hivescriptsdirectory}/staging/insert_overwrite_lnd_stg.hql</script>
			<param>IVIS_HIVE_DATABASE=${ivis_hive_database}</param>
            <param>STAGE_TABLE=${scp_web_usr_access_vw_stg_tablename}</param>
            <param>LANDING_TABLE=${scp_web_usr_access_vw_lnd_tablename}</param>
        </hive>
        <ok to="join_insert_overwrite_lnd_stg"/>
        <error to="failureEmail"/>
    </action>
	
	
	     <!-- The hive scripts does  insert overwrite to tables in staging area-->
    <action name="insert_overwrite_usr_permission_master" cred="hcat_creds">
        <hive xmlns="uri:oozie:hive-action:0.2">
		 <job-tracker>${jobTracker}</job-tracker>
         <name-node>${nameNode}</name-node>
		<prepare>
              <delete path="${nameNode}${usr_permission_master_staging_location}/*"/>
        </prepare>
		 <configuration>
                <property>
                    <name>mapred.job.queue.name</name>
                    <value>${queueName}</value>
                </property>
         </configuration>
            <script>${hivescriptsdirectory}/staging/insert_overwrite_lnd_stg.hql</script>
			<param>IVIS_HIVE_DATABASE=${ivis_hive_database}</param>
            <param>STAGE_TABLE=${usr_permission_master_stg_tablename}</param>
            <param>LANDING_TABLE=${usr_permission_master_lnd_tablename}</param>
        </hive>
        <ok to="join_insert_overwrite_lnd_stg"/>
        <error to="failureEmail"/>
    </action>
	
	
	<join name="join_insert_overwrite_lnd_stg" to="phoenix_delete_scp_web_usr_access_vw"/>
	
	<!-- The Pig scripts does --> 
    <action name="phoenix_delete_scp_web_usr_access_vw" cred="hcat_creds,hbase">
       <shell xmlns="uri:oozie:shell-action:0.1">
		 <job-tracker>${jobTracker}</job-tracker>
         <name-node>${nameNode}</name-node>
		 <exec>phx_tbl_del.sh</exec>
		 <argument>${phoenix_schema_env}</argument>
		 <argument>${phoenix_hbase_cluster}</argument>
		 <argument>${scp_web_usr_access_vw_stg_tablename}</argument>
		 <file>${shellscriptsdirectory}/phoenix/phx_tbl_del.sh#phx_tbl_del.sh</file>
        </shell>
        <ok to="phoenix_delete_usr_permission_master"/>
        <error to="failureEmail"/>
    </action>
	
	<!-- The Pig scripts does --> 
    <action name="phoenix_delete_usr_permission_master" cred="hcat_creds,hbase">
       <shell xmlns="uri:oozie:shell-action:0.1">
		 <job-tracker>${jobTracker}</job-tracker>
         <name-node>${nameNode}</name-node>
		 <exec>phx_tbl_del.sh</exec>
		 <argument>${phoenix_schema_env}</argument>
		 <argument>${phoenix_hbase_cluster}</argument>
		 <argument>${usr_permission_master_stg_tablename}</argument>
		 <file>${shellscriptsdirectory}/phoenix/phx_tbl_del.sh#phx_tbl_del.sh</file>
        </shell>
        <ok to="stg_phx_data_move"/>
        <error to="failureEmail"/>
    </action>
	
	<fork name="stg_phx_data_move">
		<path start="stg_phx_scp_web_usr_access_vw"/>
		<path start="stg_phx_usr_permission_master"/>
	</fork>
	
		 <!-- The Pig scripts does --> 
    <action name="stg_phx_scp_web_usr_access_vw" cred="hcat_creds,hbase">
        <pig>
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <script>${pigscriptsdirectory}/phoenix/scp_web_usr_access_vw_phx.pig</script>
			<param>PHX_JAR_LOC=${phoenix_client_jar}</param>
			<param>PHOENIX_SCHEMA_ENV=${phoenix_schema_env}</param>
			<param>PHOENIX_HBASE_CLUSTER=${phoenix_hbase_cluster}</param>
			<param>IVIS_HIVE_DATABASE=${ivis_hive_database}</param>
       </pig>
        <ok to="join_stg_phx_data_move"/>
		<error to="failureEmail"/>
    </action>

		 <!-- The Pig scripts does --> 
    <action name="stg_phx_usr_permission_master" cred="hcat_creds,hbase">
        <pig>
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <script>${pigscriptsdirectory}/phoenix/usr_permission_master_phx.pig</script>
			<param>PHX_JAR_LOC=${phoenix_client_jar}</param>
			<param>PHOENIX_SCHEMA_ENV=${phoenix_schema_env}</param>
			<param>PHOENIX_HBASE_CLUSTER=${phoenix_hbase_cluster}</param>
			<param>IVIS_HIVE_DATABASE=${ivis_hive_database}</param>
		</pig>
        <ok to="join_stg_phx_data_move"/>
		<error to="failureEmail"/>
    </action>

	<join name="join_stg_phx_data_move" to="end"/>

	 
   <!-- In the event of failure, send an email to a larger group with some debugging info -->
    <action name="failureEmail">
        <email xmlns="uri:oozie:email-action:0.1">
            <to>${jobFailureEmails}</to>
            <subject> ${cluster_name} - JOB FAILURE ${wf:id()}</subject>
            <body>
                Error message is: [${wf:errorMessage(wf:lastErrorNode())}]

                Oozie job id: ${wf:id()}

                External Job Id is ${wf:actionExternalId(wf:lastErrorNode())}
		  
				Job log location is
				http://sn01.nonprod.scn:19888/jobhistory/job/${wf:actionExternalId(wf:lastErrorNode())}	
			
                This is an automatic e-mail generated by the job.
            </body>
        </email>
        <ok to="kill"/>
        <error to="kill"/>
    </action>

   
    <kill name="kill">
        <message>Action failed, error message[${wf:errorMessage(wf:lastErrorNode())}]</message>
    </kill>
	
    <end name="end"/>
</workflow-app>
